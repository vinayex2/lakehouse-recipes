{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5bb6a72-fae1-4a54-83a5-f60b61f8b701",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Connections to Storage options\n",
    "- Storage Account Keys\n",
    "- Azure Groups and Credential passthrough\n",
    "- SAS Tokens\n",
    "- Service principals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa9caa55-321c-4832-9fa4-5432338b83b1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Cleaning Beginnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a317b376-91dd-4ac0-822f-30701fa51de0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.rm('/FileStore/tables/ingestion/raw',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4795f84e-0bc0-471b-b766-3881c6c7d9cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "org.apache.spark.sql.catalyst.analysis.NoSuchNamespaceException: [SCHEMA_NOT_FOUND] The schema `lakehouse` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
       "If you did not qualify the name with a catalog, verify the current_schema() output, or qualify the name with the correct catalog.\n",
       "To tolerate the error on drop use DROP SCHEMA IF EXISTS. SQLSTATE: 42704\n",
       "\tat org.apache.spark.sql.errors.QueryCompilationErrors$.noSuchNamespaceError(QueryCompilationErrors.scala:1725)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.DropNamespaceExec.run(DropNamespaceExec.scala:48)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$2(V2CommandExec.scala:48)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:48)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n",
       "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:56)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$5(QueryExecution.scala:382)\n",
       "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$4(QueryExecution.scala:382)\n",
       "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:169)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:382)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$9(SQLExecution.scala:400)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:717)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:278)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:165)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:654)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:378)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1152)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:374)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:325)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:371)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:347)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:505)\n",
       "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:505)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:40)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:379)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:375)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n",
       "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:481)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:347)\n",
       "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:436)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:347)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:284)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:281)\n",
       "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:339)\n",
       "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:131)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1187)\n",
       "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n",
       "\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1187)\n",
       "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:122)\n",
       "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:959)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:947)\n",
       "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:982)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:292)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:392)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:414)\n",
       "\tat scala.collection.immutable.List.map(List.scala:293)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:409)\n",
       "\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.repl(JupyterDriverLocal.scala:977)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$30(DriverLocal.scala:1141)\n",
       "\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$25(DriverLocal.scala:1132)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:88)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:88)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1076)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1488)\n",
       "\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:767)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:931)\n",
       "\tat scala.util.Try$.apply(Try.scala:213)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:920)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:952)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:717)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:784)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:586)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:512)\n",
       "\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:306)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "[SCHEMA_NOT_FOUND] The schema `lakehouse` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a catalog, verify the current_schema() output, or qualify the name with the correct catalog.\nTo tolerate the error on drop use DROP SCHEMA IF EXISTS. SQLSTATE: 42704"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "SCHEMA_NOT_FOUND",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "sqlState": "42704",
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "org.apache.spark.sql.catalyst.analysis.NoSuchNamespaceException: [SCHEMA_NOT_FOUND] The schema `lakehouse` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a catalog, verify the current_schema() output, or qualify the name with the correct catalog.\nTo tolerate the error on drop use DROP SCHEMA IF EXISTS. SQLSTATE: 42704\n\tat org.apache.spark.sql.errors.QueryCompilationErrors$.noSuchNamespaceError(QueryCompilationErrors.scala:1725)\n\tat org.apache.spark.sql.execution.datasources.v2.DropNamespaceExec.run(DropNamespaceExec.scala:48)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$2(V2CommandExec.scala:48)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandWithAetherOff(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:191)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.$anonfun$result$1(V2CommandExec.scala:48)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:47)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:45)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:56)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$5(QueryExecution.scala:382)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$4(QueryExecution.scala:382)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:169)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$3(QueryExecution.scala:382)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$9(SQLExecution.scala:400)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:717)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:278)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:165)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:654)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$2(QueryExecution.scala:378)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1152)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:374)\n\tat org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$withMVTagsIfNecessary(QueryExecution.scala:325)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:371)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:347)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:505)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:85)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:505)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:379)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:375)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:40)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:481)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:347)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:436)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:347)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:284)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:281)\n\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:339)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:131)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1187)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)\n\tat org.apache.spark.sql.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1187)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:122)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$4(SparkSession.scala:959)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1180)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:947)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:982)\n\tat com.databricks.backend.daemon.driver.DriverLocal$DbClassicStrategy.executeSQLQuery(DriverLocal.scala:292)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSQLSubCommand(DriverLocal.scala:392)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$executeSql$1(DriverLocal.scala:414)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat com.databricks.backend.daemon.driver.DriverLocal.executeSql(DriverLocal.scala:409)\n\tat com.databricks.backend.daemon.driver.JupyterDriverLocal.repl(JupyterDriverLocal.scala:977)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$30(DriverLocal.scala:1141)\n\tat com.databricks.unity.EmptyHandle$.runWith(UCSHandle.scala:128)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$25(DriverLocal.scala:1132)\n\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionContext(DriverLocal.scala:88)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n\tat com.databricks.backend.daemon.driver.DriverLocal.withAttributionTags(DriverLocal.scala:88)\n\tat com.databricks.backend.daemon.driver.DriverLocal.$anonfun$execute$1(DriverLocal.scala:1076)\n\tat com.databricks.backend.daemon.driver.DriverLocal$.$anonfun$maybeSynchronizeExecution$4(DriverLocal.scala:1488)\n\tat com.databricks.backend.daemon.driver.DriverLocal.execute(DriverLocal.scala:767)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$2(DriverWrapper.scala:931)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.$anonfun$tryExecutingCommand$1(DriverWrapper.scala:920)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.tryExecutingCommand(DriverWrapper.scala:952)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommandAndGetError(DriverWrapper.scala:717)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.executeCommand(DriverWrapper.scala:784)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInnerLoop(DriverWrapper.scala:586)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.runInner(DriverWrapper.scala:512)\n\tat com.databricks.backend.daemon.driver.DriverWrapper.run(DriverWrapper.scala:306)\n\tat java.lang.Thread.run(Thread.java:750)\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DROP SCHEMA lakehouse CASCADE;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47a7faa0-d138-4d32-9aa6-c15c0841f48e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Create Table with CDF Enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecbe93c6-d98c-422f-bc49-562bc0cd119d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE SCHEMA lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a95c029-5336-47e7-a8e1-1a89e07a2d44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS lakehouse.watermark (\n",
    "  schemaName STRING,\n",
    "  tableName STRING,\n",
    "  watermarkType STRING,\n",
    "  timestampWatermark TIMESTAMP,\n",
    "  integerWatermark INT,\n",
    "  bigIntWatermark BIGINT,\n",
    "  stringWatermark STRING\n",
    ") TBLPROPERTIES (delta.enableChangeDataFeed = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eec7c9aa-fec1-4fd0-8329-f3791b29868b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>version</th><th>timestamp</th><th>userId</th><th>userName</th><th>operation</th><th>operationParameters</th><th>job</th><th>notebook</th><th>clusterId</th><th>readVersion</th><th>isolationLevel</th><th>isBlindAppend</th><th>operationMetrics</th><th>userMetadata</th><th>engineInfo</th></tr></thead><tbody><tr><td>0</td><td>2024-08-26T03:36:50Z</td><td>7285002445872367</td><td>vasaicrow@gmail.com</td><td>CREATE TABLE</td><td>Map(partitionBy -> [], clusterBy -> [], description -> null, isManaged -> true, properties -> {\"delta.enableChangeDataFeed\":\"true\"}, statsOnLoad -> false)</td><td>null</td><td>List(3780456485084141)</td><td>0826-031505-kc4bi39o</td><td>null</td><td>WriteSerializable</td><td>true</td><td>Map()</td><td>null</td><td>Databricks-Runtime/15.4.x-scala2.12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         "2024-08-26T03:36:50Z",
         "7285002445872367",
         "vasaicrow@gmail.com",
         "CREATE TABLE",
         {
          "clusterBy": "[]",
          "description": null,
          "isManaged": "true",
          "partitionBy": "[]",
          "properties": "{\"delta.enableChangeDataFeed\":\"true\"}",
          "statsOnLoad": "false"
         },
         null,
         [
          "3780456485084141"
         ],
         "0826-031505-kc4bi39o",
         null,
         "WriteSerializable",
         true,
         {},
         null,
         "Databricks-Runtime/15.4.x-scala2.12"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 44
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "version",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "timestamp",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "userId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "userName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operation",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "operationParameters",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "job",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"jobId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobName\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobRunId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"runId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"jobOwnerId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"triggerType\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "notebook",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"notebookId\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "clusterId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "readVersion",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "isolationLevel",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isBlindAppend",
         "type": "\"boolean\""
        },
        {
         "metadata": "{}",
         "name": "operationMetrics",
         "type": "{\"type\":\"map\",\"keyType\":\"string\",\"valueType\":\"string\",\"valueContainsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "userMetadata",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "engineInfo",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY lakehouse.watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "714c2d0b-450e-4d51-a782-cd1a7a71e581",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Using Python to enable CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "939b90a0-ec03-41ee-8b50-7983441321f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def TurnCDFOn(schema, table):   \n",
    "    spark.sql(f\"ALTER TABLE {schema}.{table} SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")\n",
    "    print(f'TurnCDFOn: Turned CDF on for {schema}.{table}')\n",
    "\n",
    "def TurnCDFOff(schema, table):   \n",
    "    spark.sql(f\"ALTER TABLE {schema}.{table} SET TBLPROPERTIES (delta.enableChangeDataFeed = false)\")\n",
    "    print(f'TurnCDFOn: Turned CDF off for {schema}.{table}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16beeca5-2dbc-4075-9913-86b7bf7d8920",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TurnCDFOn: Turned CDF on for lakehouse.watermark\n"
     ]
    }
   ],
   "source": [
    "# TurnCDFOff('lakehouse','watermark')\n",
    "TurnCDFOn('lakehouse','watermark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b472f11c-ab3e-4d61-8585-5c358eb7623d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def isCDFOn(schema,table):\n",
    "    statement = f\"SHOW TBLPROPERTIES {schema}.{table}\"\n",
    "    print(statement)\n",
    "    tlbPropertiesDF = spark.sql(statement)\n",
    "    tblProperties = tlbPropertiesDF.where(tlbPropertiesDF.key == \"delta.enableChangeDataFeed\").collect()\n",
    "    nummatching = len(tblProperties)\n",
    "    if (nummatching == 0):\n",
    "        print(f\"IsCDFOn: No CDF Table properties found {schema}.{table}\")\n",
    "        return False\n",
    "    elif nummatching == 1:\n",
    "        isOn = tblProperties[0][1]\n",
    "        if isOn != \"true\":\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    print(f\"IsCDFOn: CDF- This should not happen. Should be 1 {schema}.{table}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c34afea5-446f-41bc-aa5e-c854247639ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHOW TBLPROPERTIES lakehouse.watermark\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isCDFOn('lakehouse','watermark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad78944b-f5f6-458a-8552-11f88b8985e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def EnsureCDFisOn(schema,table):\n",
    "    isOn = isCDFOn(schema,table)\n",
    "    if isOn:\n",
    "        print(schema,table,\"EnsureCDFisOn: CDF already on\")\n",
    "        return\n",
    "    TurnCDFOn(schema,table)\n",
    "    print(schema,table,\"Turned CDF On\")\n",
    "\n",
    "def TurnCDFOnForAllTables():\n",
    "    schemasDF = spark.sql(\"SHOW SCHEMAS\")\n",
    "    results = []\n",
    "    for schema in schemasDF.collect():\n",
    "        if schema['databaseName'] != 'default':\n",
    "            tablesDF = spark.sql(f\"show tables from {schema['databaseName']}\")\n",
    "            for table in tablesDF.collect():                \n",
    "                if table['isTemporary'] == False:\n",
    "                    EnsureCDFisOn(table['database'],table['tableName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bc768e0-5cf2-4178-bb94-8dbf081a93fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHOW TBLPROPERTIES lakehouse.watermark\nlakehouse watermark EnsureCDFisOn: CDF already on\n"
     ]
    }
   ],
   "source": [
    "TurnCDFOnForAllTables()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "465cfff0-34ec-4566-ac5e-3928ebee918d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Loading Files using self-managed watermarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "501c1ecb-fe63-43a3-a64a-8615794cb71f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.mkdirs('/FileStore/tables/ingestion')\n",
    "dbutils.fs.mkdirs('/FileStore/tables/ingestion/raw')\n",
    "dbutils.fs.mkdirs('/FileStore/tables/ingestion/raw/updates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d91fd77-fbd5-4da6-804c-6251b6e8a867",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.fs.rm('/FileStore/tables/ingestion/raw',True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4a0c285-1e5a-4a14-8690-c14fc4839872",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Recursive Directory Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13ced12b-c7af-4c5e-b2c8-2678def43f82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def RecursiveDirectoryToDataFrame(path,allFiles=None):\n",
    "    createDataFrame = False\n",
    "    if allFiles is None:\n",
    "        createDataFrame = True\n",
    "        allFiles=[]\n",
    "    ls = dbutils.fs.ls(path)\n",
    "    for l in ls:\n",
    "        if (l.isFile()):\n",
    "            allFiles.append(l)\n",
    "        elif l.isDir():\n",
    "            if l != path:\n",
    "                RecursiveDirectoryToDataFrame(l.path,allFiles)\n",
    "    if createDataFrame:\n",
    "        return spark.createDataFrame(allFiles)\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9655e2b8-7f95-4645-8df4-a3c490afcb22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/ingestion/raw/employees.csv</td><td>employees.csv</td><td>335</td><td>1724643436000</td></tr><tr><td>dbfs:/FileStore/tables/ingestion/raw/updates/employees_updated.csv</td><td>employees_updated.csv</td><td>336</td><td>1724643522000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/tables/ingestion/raw/employees.csv",
         "employees.csv",
         335,
         1724643436000
        ],
        [
         "dbfs:/FileStore/tables/ingestion/raw/updates/employees_updated.csv",
         "employees_updated.csv",
         336,
         1724643522000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath = 'dbfs:/FileStore/tables/ingestion/raw'\n",
    "allSourceFilesDf =RecursiveDirectoryToDataFrame(filepath)\n",
    "display(allSourceFilesDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a583d7e1-de89-449e-bfd1-45af85fa1663",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import datetime\n",
    "def GetWatermark(schema,table):\n",
    "    watermarktable = \"lakehouse.watermark\"\n",
    "    df = spark.read.table(watermarktable)\n",
    "    display(df)\n",
    "    df = df.where((F.col(\"schemaName\") == schema) & (F.col(\"tableName\") == table))\n",
    "    df.cache()\n",
    "    count = df.count()\n",
    "    if count == 1:\n",
    "        return df\n",
    "    elif count == 0:\n",
    "        updateWaterMarkTableSchema = \"schemaName STRING,tableName STRING,watermarkType STRING,timestampWatermark TIMESTAMP,integerWatermark INT,bigIntWatermark BIGINT,stringWatermark STRING\"\n",
    "        updateList = [{\n",
    "            \"schemaName\":schema, \n",
    "            \"tableName\":table, \n",
    "            \"watermarkType\":\"bigint\", \n",
    "            \"timestampWatermark\":None,\n",
    "            \"integerWatermark\":None, \n",
    "            \"bigIntWatermark\":0, \n",
    "            \"stringWatermark\":None\n",
    "        }]\n",
    "        dfUpdates = spark.createDataFrame(updateList,updateWaterMarkTableSchema)\n",
    "        dfUpdates.show()\n",
    "        return dfUpdates\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65c4041a-1ea8-47eb-af02-88471f630812",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>schemaName</th><th>tableName</th><th>watermarkType</th><th>timestampWatermark</th><th>integerWatermark</th><th>bigIntWatermark</th><th>stringWatermark</th></tr></thead><tbody><tr><td>lakehouse</td><td>employees</td><td>bigint</td><td>null</td><td>null</td><td>0</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "lakehouse",
         "employees",
         "bigint",
         null,
         null,
         0,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "schemaName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tableName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "watermarkType",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "timestampWatermark",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "integerWatermark",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "bigIntWatermark",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "stringWatermark",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "startingWatermarkDF = GetWatermark(\"lakehouse\",\"employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "426e6171-6dba-4d3a-8c7c-d9f1a435771e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta import * \n",
    "\n",
    "def UpsertWaterMark(dfUpdates):\n",
    "    watermarktable = 'lakehouse.watermark'\n",
    "    print(\"watermarkTable\", watermarktable)\n",
    "    watermark = DeltaTable.forName(spark, tableOrViewName=watermarktable)\n",
    "    watermark.alias('watermark').merge(\n",
    "        dfUpdates.alias('updates'), 'watermark.schemaName = updates.schemaName AND watermark.tableName = updates.tableName').whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ae3a2b2-6f8f-4d0f-93a6-a711ebf3d62b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watermarkTable lakehouse.watermark\n"
     ]
    }
   ],
   "source": [
    "UpsertWaterMark(startingWatermarkDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "062cd7f0-8ab5-449e-8311-f0688a0d11d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def getWaterMarkValue(startingWatermarkDF):\n",
    "    watermarkRow = startingWatermarkDF.collect()[0]\n",
    "    watermarktype = watermarkRow.watermarkType\n",
    "    print(watermarktype)\n",
    "    if watermarktype == \"bigint\":\n",
    "        watermarkvalue = watermarkRow.bigIntWatermark\n",
    "    elif watermarktype == 'timestamp':\n",
    "        watermarkvalue = watermarkRow.timestampWatermark\n",
    "    elif watermarktype == 'integer':\n",
    "        watermarkvalue = watermarkRow.integerWatermark\n",
    "    elif watermarktype == 'string':\n",
    "        watermarkvalue = watermarkRow.stringWatermark\n",
    "    else:\n",
    "        print(\"Unknown watermark type\", watermarktype)\n",
    "        watermarkvalue = None\n",
    "    return watermarkvalue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc8b4b49-9f37-413e-9329-d2794296f80a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Update Watermark value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3486389b-3034-4ae6-8410-bfde9bf04073",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "def UpdatewatermarkValue(watermarkDF,maxValue):\n",
    "  print(maxValue)\n",
    "  watermarkRow = startingWatermarkDF.collect()[0]\n",
    "  watermarkDF.createOrReplaceTempView('tempWatermarkRow')\n",
    "  watermarktype = watermarkRow.watermarkType\n",
    "  if watermarktype == \"bigint\":\n",
    "      watermarkDF = watermarkDF.withColumn(\"bigIntWatermark\",lit(maxValue))\n",
    "  elif watermarktype == 'timestamp':\n",
    "      watermarkDF = watermarkDF.withColumn(\"timestampWatermark\",lit(maxValue))\n",
    "  elif watermarktype == 'integer':\n",
    "      watermarkDF = watermarkDF.withColumn(\"integerWatermark\",lit(maxValue))\n",
    "  elif watermarktype == 'string':\n",
    "      watermarkDF = watermarkDF.withColumn(\"stringWatermark\",lit(maxValue))\n",
    "  return watermarkDF\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9d996bc-a78f-4eda-8d5c-bcefcab352ac",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Get Source files into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22f8deb7-3628-40c7-9365-fc54a8628da3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def GetSourceDataFrame(path,fileformat,watermarkColumn,schema,table):\n",
    "  allSourceFilesDF = RecursiveDirectoryToDataFrame(path)\n",
    "  startingWatermarkDF = GetWatermark(schema,table).cache()\n",
    "  if startingWatermarkDF is None or startingWatermarkDF.count() != 1:\n",
    "    print(\"Error: null returned from GetWatermark or rows not 1\")\n",
    "    return None\n",
    "  watermarkValue = getWaterMarkValue(startingWatermarkDF)  \n",
    "  if watermarkValue is None:\n",
    "    print(\"Error getting watermark value\")  \n",
    "  # display(watermarkValue)\n",
    "  filteredDF = allSourceFilesDf.where(F.col(watermarkColumn) > watermarkValue).orderBy(F.col(watermarkColumn)).cache()\n",
    "  # return allSourceFilesDf,watermarkValue\n",
    "  # display(allSourceFilesDf)\n",
    "  # display(filteredDF)\n",
    "  recordsDF = None\n",
    "  for f in filteredDF.collect():\n",
    "    path = f[\"path\"]\n",
    "    dfRecords = spark.read.load(path,format=fileformat,header=True)\n",
    "    if recordsDF is None:\n",
    "      recordsDF = dfRecords\n",
    "    else:\n",
    "      recordsDF = recordsDF.union(dfRecords)\n",
    "  recordsDF = recordsDF.cache()\n",
    "  maxValue = filteredDF.agg({watermarkColumn:\"max\"}).collect()[0]\n",
    "  return recordsDF,maxValue\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74ce1959-77af-4d87-972e-8230dab152da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.fs.rm(filepath,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0ba77a5-2ca8-43a7-a6c7-393301e0ef42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>schemaName</th><th>tableName</th><th>watermarkType</th><th>timestampWatermark</th><th>integerWatermark</th><th>bigIntWatermark</th><th>stringWatermark</th></tr></thead><tbody><tr><td>lakehouse</td><td>employees</td><td>bigint</td><td>null</td><td>null</td><td>1724643436000</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "lakehouse",
         "employees",
         "bigint",
         null,
         null,
         1724643436000,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "schemaName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tableName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "watermarkType",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "timestampWatermark",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "integerWatermark",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "bigIntWatermark",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "stringWatermark",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigint\nRow(max(modificationTime)=1724643522000)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmPId</th><th>FirstName</th><th>LastName</th><th>Address1</th><th>CreatedOn</th><th>ModifiedOn</th></tr></thead><tbody><tr><td>1</td><td>Leonardo</td><td>da Vinci</td><td>123 First St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>2</td><td>Napoleon</td><td>Bonaparte</td><td>234 Second St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>3</td><td>Charles</td><td>Darwin</td><td>345 Third St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>4</td><td>Albert</td><td>Einstein</td><td>456 Fourth St.</td><td>12/31/2024</td><td>10/31/2025</td></tr><tr><td>5</td><td>Thomas</td><td>Jefferson</td><td>678 Fifth St.</td><td>12/31/2024</td><td>12/31/2024</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "1",
         "Leonardo",
         "da Vinci",
         "123 First St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "2",
         "Napoleon",
         "Bonaparte",
         "234 Second St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "3",
         "Charles",
         "Darwin",
         "345 Third St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "4",
         "Albert",
         "Einstein",
         "456 Fourth St.",
         "12/31/2024",
         "10/31/2025"
        ],
        [
         "5",
         "Thomas",
         "Jefferson",
         "678 Fifth St.",
         "12/31/2024",
         "12/31/2024"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmPId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "FirstName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "LastName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Address1",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CreatedOn",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ModifiedOn",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sourcePath = filepath\n",
    "watermarkColumn = 'modificationTime'\n",
    "fileformat = 'csv'\n",
    "schema = 'lakehouse'\n",
    "table = 'employees'\n",
    "recordsDf,maxValue = GetSourceDataFrame(sourcePath,fileformat,watermarkColumn,schema,table)\n",
    "print(maxValue)\n",
    "display(recordsDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6fe4c36-ee82-4606-9529-7e1b27f63f13",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Incremental Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e28a704b-7f26-4bc0-b34f-54eda7fdea0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def IncrementalUpdate(path,fileformat,fileWatermarkColumn,schema,table,tablePath,tableComment = \"bronze table \" + table):\n",
    "    recordsDf,maxValue = GetSourceDataFrame(path,fileformat,fileWatermarkColumn,schema,table)\n",
    "    fullTableName = '`'+schema+\"`.`Bronze_\" + table+'`'\n",
    "    print(f\"{fullTableName} will be updated with {recordsDf.count()} files\")\n",
    "    targetTable = None\n",
    "    try:\n",
    "        targetTable = DeltaTable.forName(spark,tableOrViewName=fullTableName)\n",
    "    except:\n",
    "        print(\"Exceptions getting table-it probably doesnt exist\")\n",
    "    if targetTable is not None:\n",
    "        print('Exists')\n",
    "        recordsDf.write.mode('append').format(\"delta\").saveAsTable(fullTableName)\n",
    "    else:\n",
    "        print(\"Table doesnt exist yet\")\n",
    "        recordsDf.write.mode('overwrite').option(\"path\",tablePath).option('mergeSchema',True).option('comments',tableComment).format(\"delta\").saveAsTable(fullTableName)\n",
    "        EnsureCDFisOn(schema,\"`Bronze_\" + table+'`')\n",
    "    watermarkDf = UpdatewatermarkValue(startingWatermarkDF,maxValue[0])\n",
    "    updateResults = UpsertWaterMark(watermarkDf)\n",
    "    display(updateResults) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa8d0135-1aec-4f49-9d98-2b405aadacd0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>schemaName</th><th>tableName</th><th>watermarkType</th><th>timestampWatermark</th><th>integerWatermark</th><th>bigIntWatermark</th><th>stringWatermark</th></tr></thead><tbody><tr><td>lakehouse</td><td>employees</td><td>bigint</td><td>null</td><td>null</td><td>0</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "lakehouse",
         "employees",
         "bigint",
         null,
         null,
         0,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "schemaName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tableName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "watermarkType",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "timestampWatermark",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "integerWatermark",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "bigIntWatermark",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "stringWatermark",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigint\n`lakehouse`.`Bronze_employees` will be updated with 5 files\nExceptions getting table-it probably doesnt exist\nTable doesnt exist yet\nSHOW TBLPROPERTIES lakehouse.`Bronze_employees`\nIsCDFOn: No CDF Table properties found lakehouse.`Bronze_employees`\nTurnCDFOn: Turned CDF on for lakehouse.`Bronze_employees`\nlakehouse `Bronze_employees` Turned CDF On\n1724643436000\nwatermarkTable lakehouse.watermark\n"
     ]
    }
   ],
   "source": [
    "sourcePath = filepath\n",
    "tablePath = 'dbfs:/FileStore/tables/ingestion/bronze/employee'\n",
    "watermarkColumn = 'modificationTime'\n",
    "fileformat = 'csv'\n",
    "schema = 'lakehouse'\n",
    "table = 'employees'\n",
    "IncrementalUpdate(sourcePath,fileformat,watermarkColumn,schema,table,tablePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6acf178b-cfa9-44fa-b2e1-a2822aa2722d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>schemaName</th><th>tableName</th><th>watermarkType</th><th>timestampWatermark</th><th>integerWatermark</th><th>bigIntWatermark</th><th>stringWatermark</th></tr></thead><tbody><tr><td>lakehouse</td><td>employees</td><td>bigint</td><td>null</td><td>null</td><td>1724643436000</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "lakehouse",
         "employees",
         "bigint",
         null,
         null,
         1724643436000,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 78
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "schemaName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tableName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "watermarkType",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "timestampWatermark",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "integerWatermark",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "bigIntWatermark",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "stringWatermark",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from lakehouse.watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5dcd60f8-61f6-4415-9e65-8400f344be7a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Added Update File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20c5a622-ac89-4c02-84cf-67a8321f006a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>schemaName</th><th>tableName</th><th>watermarkType</th><th>timestampWatermark</th><th>integerWatermark</th><th>bigIntWatermark</th><th>stringWatermark</th></tr></thead><tbody><tr><td>lakehouse</td><td>employees</td><td>bigint</td><td>null</td><td>null</td><td>1724643436000</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "lakehouse",
         "employees",
         "bigint",
         null,
         null,
         1724643436000,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "schemaName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tableName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "watermarkType",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "timestampWatermark",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "integerWatermark",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "bigIntWatermark",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "stringWatermark",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigint\n`lakehouse`.`Bronze_employees` will be updated with 5 files\nExists\n1724643522000\nwatermarkTable lakehouse.watermark\n"
     ]
    }
   ],
   "source": [
    "sourcePath = filepath\n",
    "tablePath = 'dbfs:/FileStore/tables/ingestion/bronze/employee'\n",
    "watermarkColumn = 'modificationTime'\n",
    "fileformat = 'csv'\n",
    "schema = 'lakehouse'\n",
    "table = 'employees'\n",
    "IncrementalUpdate(sourcePath,fileformat,watermarkColumn,schema,table,tablePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0ad4d4f-a176-41a8-9670-0c7f3a9cc753",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>schemaName</th><th>tableName</th><th>watermarkType</th><th>timestampWatermark</th><th>integerWatermark</th><th>bigIntWatermark</th><th>stringWatermark</th></tr></thead><tbody><tr><td>lakehouse</td><td>employees</td><td>bigint</td><td>null</td><td>null</td><td>1724643522000</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "lakehouse",
         "employees",
         "bigint",
         null,
         null,
         1724643522000,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 92
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "schemaName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tableName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "watermarkType",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "timestampWatermark",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "integerWatermark",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "bigIntWatermark",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "stringWatermark",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from lakehouse.watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae32075d-e433-48dc-a3fd-0ac94fc3446c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmPId</th><th>FirstName</th><th>LastName</th><th>Address1</th><th>CreatedOn</th><th>ModifiedOn</th></tr></thead><tbody><tr><td>1</td><td>Leonardo</td><td>daVinci</td><td>123 First St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>2</td><td>Napoleon</td><td>Bonaparte</td><td>234 Second St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>3</td><td>Charles</td><td>Darwin</td><td>345 Third St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>4</td><td>Albert</td><td>Einstein</td><td>456 Fourth St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>5</td><td>Thomas</td><td>Jefferson</td><td>678 Fifth St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>1</td><td>Leonardo</td><td>da Vinci</td><td>123 First St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>2</td><td>Napoleon</td><td>Bonaparte</td><td>234 Second St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>3</td><td>Charles</td><td>Darwin</td><td>345 Third St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>4</td><td>Albert</td><td>Einstein</td><td>456 Fourth St.</td><td>12/31/2024</td><td>10/31/2025</td></tr><tr><td>5</td><td>Thomas</td><td>Jefferson</td><td>678 Fifth St.</td><td>12/31/2024</td><td>12/31/2024</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "1",
         "Leonardo",
         "daVinci",
         "123 First St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "2",
         "Napoleon",
         "Bonaparte",
         "234 Second St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "3",
         "Charles",
         "Darwin",
         "345 Third St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "4",
         "Albert",
         "Einstein",
         "456 Fourth St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "5",
         "Thomas",
         "Jefferson",
         "678 Fifth St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "1",
         "Leonardo",
         "da Vinci",
         "123 First St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "2",
         "Napoleon",
         "Bonaparte",
         "234 Second St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "3",
         "Charles",
         "Darwin",
         "345 Third St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "4",
         "Albert",
         "Einstein",
         "456 Fourth St.",
         "12/31/2024",
         "10/31/2025"
        ],
        [
         "5",
         "Thomas",
         "Jefferson",
         "678 Fifth St.",
         "12/31/2024",
         "12/31/2024"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 93
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmPId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "FirstName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "LastName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Address1",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CreatedOn",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ModifiedOn",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from lakehouse.bronze_employees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec967d8f-4f8a-462d-acc0-8e364c73884b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Full Load into Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "521d5954-9e5a-42fd-9f32-06d1b01c377b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def FullLoadToBronze(sourcePath,fileFormat, schema,table,tablePath,tableSchema=\"\",tableComment =None):\n",
    "    if tableComment is None:\n",
    "        tableComment = \"Bronze version of \" + table\n",
    "    df = spark.read.option(\"recursiveFileLookup\",\"true\").option('header','true').load(sourcePath,format=fileFormat)\n",
    "    fullTableName = '`'+schema+\"`.`Bronze_\" + table+'`'\n",
    "    df.write.mode(\"overwrite\").option('overwriteSchema',\"true\").option(\"path\",tablePath).option(\"comments\",tableComment).saveAsTable(fullTableName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74426e8e-3109-498d-9112-1d99e52a2381",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>tableName</th><th>isTemporary</th></tr></thead><tbody><tr><td>lakehouse</td><td>bronze_employees</td><td>false</td></tr><tr><td>lakehouse</td><td>bronze_fullload_employees</td><td>false</td></tr><tr><td>lakehouse</td><td>watermark</td><td>false</td></tr><tr><td></td><td>_sqldf</td><td>true</td></tr><tr><td></td><td>tempwatermarkrow</td><td>true</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "lakehouse",
         "bronze_employees",
         false
        ],
        [
         "lakehouse",
         "bronze_fullload_employees",
         false
        ],
        [
         "lakehouse",
         "watermark",
         false
        ],
        [
         "",
         "_sqldf",
         true
        ],
        [
         "",
         "tempwatermarkrow",
         true
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 96
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "database",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tableName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isTemporary",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SHOW TABLES IN lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffa24974-e965-4281-9c7d-11b0ee064502",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmPId</th><th>FirstName</th><th>LastName</th><th>Address1</th><th>CreatedOn</th><th>ModifiedOn</th></tr></thead><tbody><tr><td>1</td><td>Leonardo</td><td>daVinci</td><td>123 First St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>2</td><td>Napoleon</td><td>Bonaparte</td><td>234 Second St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>3</td><td>Charles</td><td>Darwin</td><td>345 Third St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>4</td><td>Albert</td><td>Einstein</td><td>456 Fourth St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>5</td><td>Thomas</td><td>Jefferson</td><td>678 Fifth St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>1</td><td>Leonardo</td><td>da Vinci</td><td>123 First St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>2</td><td>Napoleon</td><td>Bonaparte</td><td>234 Second St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>3</td><td>Charles</td><td>Darwin</td><td>345 Third St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>4</td><td>Albert</td><td>Einstein</td><td>456 Fourth St.</td><td>12/31/2024</td><td>10/31/2025</td></tr><tr><td>5</td><td>Thomas</td><td>Jefferson</td><td>678 Fifth St.</td><td>12/31/2024</td><td>12/31/2024</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "1",
         "Leonardo",
         "daVinci",
         "123 First St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "2",
         "Napoleon",
         "Bonaparte",
         "234 Second St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "3",
         "Charles",
         "Darwin",
         "345 Third St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "4",
         "Albert",
         "Einstein",
         "456 Fourth St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "5",
         "Thomas",
         "Jefferson",
         "678 Fifth St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "1",
         "Leonardo",
         "da Vinci",
         "123 First St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "2",
         "Napoleon",
         "Bonaparte",
         "234 Second St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "3",
         "Charles",
         "Darwin",
         "345 Third St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "4",
         "Albert",
         "Einstein",
         "456 Fourth St.",
         "12/31/2024",
         "10/31/2025"
        ],
        [
         "5",
         "Thomas",
         "Jefferson",
         "678 Fifth St.",
         "12/31/2024",
         "12/31/2024"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmPId",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "FirstName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "LastName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Address1",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "CreatedOn",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ModifiedOn",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sourcePath = filepath\n",
    "tablePath = 'dbfs:/FileStore/tables/ingestion/bronze/employee'\n",
    "watermarkColumn = 'modificationTime'\n",
    "fileformat = 'csv'\n",
    "schema = 'lakehouse'\n",
    "table = 'fullload_employees'\n",
    "FullLoadToBronze(sourcePath,fileformat, schema,table,tablePath)\n",
    "display(spark.sql('select * from lakehouse.bronze_fullload_employees'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2965eb02-f1b0-4fb9-8244-85ea6832e61d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Incremental Loading files using Autoloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0260f4b8-0504-46a2-a948-4550e3d5e751",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def createTableFromFile(cloudFilesFormat,sourcePath,filePath,schema,table,schemaHints=None,readOptions=None):\n",
    "    if not table.startswith(\"bronze_\"):\n",
    "        table = \"bronze_\" + table\n",
    "    schemaLocation = filePath.replace('/bronze/','/schemas_bronze/')\n",
    "    checkpointLocation = filePath.replace('/bronze/','/checkpoints_bronze/')\n",
    "    dbutils.fs.mkdirs(schemaLocation)\n",
    "    dbutils.fs.mkdirs(checkpointLocation)\n",
    "\n",
    "    #setup input stream\n",
    "    dataStreamReader = spark.readStream.format('cloudFiles').option(\"mergeSchema\",'true').option('cloudFiles.inferColumnTypes','true')\n",
    "    dataStreamReader = dataStreamReader.option('cloudFiles.format',cloudFilesFormat).option('cloudFiles.schemaLocation',schemaLocation)\n",
    "    if schemaHints is not None:\n",
    "        dataStreamReader = dataStreamReader.option('cloudFiles.schemaHints',schemaHints)\n",
    "    else:\n",
    "        dataStreamReader = dataStreamReader.option('delta.columnMappingMode.mode','name')\n",
    "    \n",
    "    if readOptions is not None:\n",
    "        dataStreamReader = dataStreamReader.option(**readOptions)\n",
    "    \n",
    "    df = dataStreamReader.load(sourcePath)\n",
    "    #Read Stream and create dataframe\n",
    "    result = (df.writeStream.trigger(once=True).format('delta').outputMode('append').option('mergeSchema','true').option('checkpointLocation',checkpointLocation).option('path',filePath).toTable(schema+\".\"+table))\n",
    "    result.awaitTermination()\n",
    "    EnsureCDFisOn(schema,table)\n",
    "    return result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a8ae6ff-6451-4b0e-a343-629e9fdd3680",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHOW TBLPROPERTIES lakehouse.bronze_employeeautoloader\nIsCDFOn: No CDF Table properties found lakehouse.bronze_employeeautoloader\nTurnCDFOn: Turned CDF on for lakehouse.bronze_employeeautoloader\nlakehouse bronze_employeeautoloader Turned CDF On\n"
     ]
    }
   ],
   "source": [
    "sourcePath = filepath\n",
    "bronzePath = 'dbfs:/FileStore/tables/ingestion/autoloader/bronze/employees'\n",
    "result = createTableFromFile('csv',sourcePath,bronzePath,'lakehouse','employeeautoloader')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "365e541d-20a4-42a0-95e2-19e3dca5dcfb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>database</th><th>tableName</th><th>isTemporary</th></tr></thead><tbody><tr><td>lakehouse</td><td>bronze_employeeautoloader</td><td>false</td></tr><tr><td>lakehouse</td><td>bronze_employees</td><td>false</td></tr><tr><td>lakehouse</td><td>bronze_fullload_employees</td><td>false</td></tr><tr><td>lakehouse</td><td>watermark</td><td>false</td></tr><tr><td></td><td>_sqldf</td><td>true</td></tr><tr><td></td><td>tempwatermarkrow</td><td>true</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "lakehouse",
         "bronze_employeeautoloader",
         false
        ],
        [
         "lakehouse",
         "bronze_employees",
         false
        ],
        [
         "lakehouse",
         "bronze_fullload_employees",
         false
        ],
        [
         "lakehouse",
         "watermark",
         false
        ],
        [
         "",
         "_sqldf",
         true
        ],
        [
         "",
         "tempwatermarkrow",
         true
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 115
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "database",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "tableName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "isTemporary",
         "type": "\"boolean\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "show tables in lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e057ea9d-50b5-433b-955a-6d03cd9d4df5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EmPId</th><th>FirstName</th><th>LastName</th><th>Address1</th><th>CreatedOn</th><th>ModifiedOn</th><th>_rescued_data</th></tr></thead><tbody><tr><td>1</td><td>Leonardo</td><td>da Vinci</td><td>123 First St.</td><td>2024-12-31</td><td>2024-12-31</td><td>null</td></tr><tr><td>2</td><td>Napoleon</td><td>Bonaparte</td><td>234 Second St.</td><td>2024-12-31</td><td>2024-12-31</td><td>null</td></tr><tr><td>3</td><td>Charles</td><td>Darwin</td><td>345 Third St.</td><td>2024-12-31</td><td>2024-12-31</td><td>null</td></tr><tr><td>4</td><td>Albert</td><td>Einstein</td><td>456 Fourth St.</td><td>2024-12-31</td><td>2025-10-31</td><td>null</td></tr><tr><td>5</td><td>Thomas</td><td>Jefferson</td><td>678 Fifth St.</td><td>2024-12-31</td><td>2024-12-31</td><td>null</td></tr><tr><td>1</td><td>Leonardo</td><td>daVinci</td><td>123 First St.</td><td>2024-12-31</td><td>2024-12-31</td><td>null</td></tr><tr><td>2</td><td>Napoleon</td><td>Bonaparte</td><td>234 Second St.</td><td>2024-12-31</td><td>2024-12-31</td><td>null</td></tr><tr><td>3</td><td>Charles</td><td>Darwin</td><td>345 Third St.</td><td>2024-12-31</td><td>2024-12-31</td><td>null</td></tr><tr><td>4</td><td>Albert</td><td>Einstein</td><td>456 Fourth St.</td><td>2024-12-31</td><td>2024-12-31</td><td>null</td></tr><tr><td>5</td><td>Thomas</td><td>Jefferson</td><td>678 Fifth St.</td><td>2024-12-31</td><td>2024-12-31</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "Leonardo",
         "da Vinci",
         "123 First St.",
         "2024-12-31",
         "2024-12-31",
         null
        ],
        [
         2,
         "Napoleon",
         "Bonaparte",
         "234 Second St.",
         "2024-12-31",
         "2024-12-31",
         null
        ],
        [
         3,
         "Charles",
         "Darwin",
         "345 Third St.",
         "2024-12-31",
         "2024-12-31",
         null
        ],
        [
         4,
         "Albert",
         "Einstein",
         "456 Fourth St.",
         "2024-12-31",
         "2025-10-31",
         null
        ],
        [
         5,
         "Thomas",
         "Jefferson",
         "678 Fifth St.",
         "2024-12-31",
         "2024-12-31",
         null
        ],
        [
         1,
         "Leonardo",
         "daVinci",
         "123 First St.",
         "2024-12-31",
         "2024-12-31",
         null
        ],
        [
         2,
         "Napoleon",
         "Bonaparte",
         "234 Second St.",
         "2024-12-31",
         "2024-12-31",
         null
        ],
        [
         3,
         "Charles",
         "Darwin",
         "345 Third St.",
         "2024-12-31",
         "2024-12-31",
         null
        ],
        [
         4,
         "Albert",
         "Einstein",
         "456 Fourth St.",
         "2024-12-31",
         "2024-12-31",
         null
        ],
        [
         5,
         "Thomas",
         "Jefferson",
         "678 Fifth St.",
         "2024-12-31",
         "2024-12-31",
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "EmPId",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "FirstName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "LastName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Address1",
         "type": "\"string\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"M/d/yyyy\"}",
         "name": "CreatedOn",
         "type": "\"date\""
        },
        {
         "metadata": "{\"__detected_date_formats\":\"M/d/yyyy\"}",
         "name": "ModifiedOn",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "_rescued_data",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(spark.sql('select * from lakehouse.bronze_employeeautoloader'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b861a382-8bc7-49a2-a2e8-858ccac97681",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>col_name</th><th>data_type</th><th>comment</th></tr></thead><tbody><tr><td>EmPId</td><td>int</td><td>null</td></tr><tr><td>FirstName</td><td>string</td><td>null</td></tr><tr><td>LastName</td><td>string</td><td>null</td></tr><tr><td>Address1</td><td>string</td><td>null</td></tr><tr><td>CreatedOn</td><td>date</td><td>null</td></tr><tr><td>ModifiedOn</td><td>date</td><td>null</td></tr><tr><td>_rescued_data</td><td>string</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "EmPId",
         "int",
         null
        ],
        [
         "FirstName",
         "string",
         null
        ],
        [
         "LastName",
         "string",
         null
        ],
        [
         "Address1",
         "string",
         null
        ],
        [
         "CreatedOn",
         "date",
         null
        ],
        [
         "ModifiedOn",
         "date",
         null
        ],
        [
         "_rescued_data",
         "string",
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 117
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{\"comment\":\"name of the column\"}",
         "name": "col_name",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"data type of the column\"}",
         "name": "data_type",
         "type": "\"string\""
        },
        {
         "metadata": "{\"comment\":\"comment of the column\"}",
         "name": "comment",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DESCRIBE lakehouse.bronze_employeeautoloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad77c7c9-a6a7-4d03-b1cf-d1e38f73133f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Loading Files via Delta Live Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7dfb2b87-ab0e-400a-8ba9-894f5c642858",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### DLT SQL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdbd3e33-355a-4882-a512-70aa8580f4da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>message</th></tr></thead><tbody><tr><td>This Delta Live Tables query is syntactically valid, but you must create a pipeline in order to define and populate your table.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "This Delta Live Tables query is syntactically valid, but you must create a pipeline in order to define and populate your table."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 118
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "message",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "-- This cannot be run interactively; need to create pipline\n",
    "CREATE STREAMING LIVE TABLE Bronze_Employee_DLT\n",
    "COMMENT \"Famous Brands Employee Table\"\n",
    "TBLPROPERTIES (\"quality\" = \"bronze\") AS\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  cloud_files(\n",
    "    'dbfs:/FileStore/tables/ingestion/',\n",
    "    'csv',\n",
    "    map(\n",
    "      'multiline',\n",
    "      'false',\n",
    "      'recursiveFileLookup',\n",
    "      'true',\n",
    "      'schemaEvolutionMode',\n",
    "      'rescue',\n",
    "      'autoMerge',\n",
    "      'true',\n",
    "      'cloudFiles.inferColumnTypes',\n",
    "      'true'\n",
    "    )\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a316865f-5471-4d57-a94a-1c53f5af47f3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### DLT Python API for Incremental Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea2d0898-23c3-4d65-a120-d628a106487d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "@dlt.table(comment=\"Famous Brands Employee Table using Python DLT API\",\n",
    "           table_properties={'delta.enableChangeDataFeed':'true','quality':'bronze'})\n",
    "def employee_dlt_python():\n",
    "    return spark.readStream.format('cloudFiles').option('multiline',\"false\").option(\"cloudFiles.format\",'json').load('dbfs:/FileStore/tables/ingestion/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cc42d2c-1ad7-4c07-8e45-e68a1469caec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Full Ingestion using DLT SQL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfac04c2-a733-4b8c-a028-4d22fa10016f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>num_affected_rows</th><th>num_inserted_rows</th></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 121
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "num_affected_rows",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "num_inserted_rows",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "CREATE OR REFRESH LIVE TABLE bronze_employees_fullload\n",
    "-- CREATE OR REPLACE TABLE lakehouse.bronze_employees_fullload\n",
    "as SELECT * FROM csv.`dbfs:/FileStore/tables/ingestion/raw/employees.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d930958e-3def-4836-9790-be5d2adcdeee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>_c0</th><th>_c1</th><th>_c2</th><th>_c3</th><th>_c4</th><th>_c5</th></tr></thead><tbody><tr><td>EmPId</td><td>FirstName</td><td>LastName</td><td>Address1</td><td>CreatedOn</td><td>ModifiedOn</td></tr><tr><td>1</td><td>Leonardo</td><td>daVinci</td><td>123 First St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>2</td><td>Napoleon</td><td>Bonaparte</td><td>234 Second St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>3</td><td>Charles</td><td>Darwin</td><td>345 Third St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>4</td><td>Albert</td><td>Einstein</td><td>456 Fourth St.</td><td>12/31/2024</td><td>12/31/2024</td></tr><tr><td>5</td><td>Thomas</td><td>Jefferson</td><td>678 Fifth St.</td><td>12/31/2024</td><td>12/31/2024</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "EmPId",
         "FirstName",
         "LastName",
         "Address1",
         "CreatedOn",
         "ModifiedOn"
        ],
        [
         "1",
         "Leonardo",
         "daVinci",
         "123 First St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "2",
         "Napoleon",
         "Bonaparte",
         "234 Second St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "3",
         "Charles",
         "Darwin",
         "345 Third St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "4",
         "Albert",
         "Einstein",
         "456 Fourth St.",
         "12/31/2024",
         "12/31/2024"
        ],
        [
         "5",
         "Thomas",
         "Jefferson",
         "678 Fifth St.",
         "12/31/2024",
         "12/31/2024"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 122
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "_c0",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_c1",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_c2",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_c3",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_c4",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "_c5",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from lakehouse.bronze_employees_fullload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bcbb99d-136c-4454-8952-ed46604014a0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Full Load using Python DLT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eba944fe-dff7-4067-87f0-384ffa9b4dff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "@dlt.table(comment=\"Famous Brands Employee Table using Python DLT API\",\n",
    "           table_properties={'delta.enableChangeDataFeed':'true','quality':'bronze'})\n",
    "def employee_dlt_python():\n",
    "    return spark.read.format('csv').load('dbfs:/FileStore/tables/ingestion/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5ebc6f2-cbe5-4b22-b868-d8a747243ead",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Streaming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6161116-2dd1-4592-897a-6c306bcbf7c4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Stream Processing with DLT Python API"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1464350001159832,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "raw_to_bronze",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
